# :rabbit: Í∞êÏ†ï Î∂ÑÏÑù & ÏúÑÎ°ú Ï±óÎ¥á, ÌÜ†Îã•ÌÜ†Îã• :ambulance:

## :computer: ÌîÑÎ°úÏ†ùÌä∏ ÏÜåÍ∞ú

### :question: Ïôú "ÌÜ†Îã•ÌÜ†Îã•"Ïù∏Í∞ÄÏöî?

- ÏÇ¨Ïö©ÏûêÎ•º ÌÜ†Îã•ÌÜ†Îã• ÏúÑÎ°úÌï¥Ï£ºÎäî ÌÜ†ÎÅº Îã•ÌÑ∞ÎùºÎäî Ï§ëÏùòÏ†Å ÏùòÎØ∏ ÏûÖÎãàÎã§.
- ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûëÏÑ±Ìïú ÌÖçÏä§Ìä∏Î•º ÌÜµÌï¥ Í∞êÏ†ïÏùÑ Î∂ÑÏÑùÌïòÍ≥†,
- Î∂ÑÏÑùÌïú Í∞êÏ†ïÏóê ÎåÄÌï¥ Í≤©Î†§ ÎòêÎäî ÏúÑÎ°úÎ•º Ìï¥Ï§çÎãàÎã§.

### :star2: ÌäπÏßï

- ÏßÅÏ†ë Ï±ÑÌåÖÏùÑ Ïπ† ÌïÑÏöî ÏóÜÏù¥ ÏùåÏÑ±ÏúºÎ°ú ÏùºÍ∏∞ ÏûëÏÑ±Ïù¥ Í∞ÄÎä•Ìï©ÎãàÎã§.
- ÏûëÏÑ±Ìïú ÏùºÍ∏∞Î•º ÌÜµÌï¥ Í∑∏ÎÇ†Ïùò Í∞êÏ†ïÏùÑ ÌååÏïÖÌï† Ïàò ÏûàÏäµÎãàÎã§.
- ÏùºÍ∏∞Ïóê ÎåÄÌïú Í∞êÏ†ïÏùÑ Í∑∏ÎûòÌîÑÎ•º ÌÜµÌï¥ ÏãúÍ∞ÅÌôîÌïòÏó¨ Ï†úÍ≥µÌï©ÎãàÎã§.

<br />

### :wind_chime: Ï£ºÏöî Í∏∞Îä•

    * üìù STT (Speech To Text)
    * üòÉ Í∞êÏ†ï Î∂ÑÏÑù (Í∏∞ÏÅ®, Ïä¨Ìîî, Ïö∞Ïö∏, Î∂ÑÎÖ∏, Î∂àÏïà, ÏùºÏÉÅ)
    * üíÜ‚Äç‚ôÄÔ∏è Í∞êÏÑ± Ï±ÑÌåÖ
    * üì¢ TTS (Text To Speech)

<br />

### :beginner: Ï£ºÏöî Í∏∞Ïà†

    * Front *
    - STT
    - TTS

    * Back *
    - JPA
    - Security

    * AI *
    - NLP
    - Deep Learning

<br />

### üî® Í∏∞Ïà† Ïä§ÌÉù

:heart: **Front End**
<img src="https://img.shields.io/badge/HTML5-E34F26?style=flat&logo=HTML5&logoColor=white"/> 
<img src="https://img.shields.io/badge/CSS-1572B6?style=flat&logo=CSS3&logoColor=white"/> 
<img src="https://img.shields.io/badge/JS-F7DF1E?style=flat&logo=JavaScript&logoColor=white"/> 
<img src="https://img.shields.io/badge/Flutter-02569B?style=flat&logo=Flutter&logoColor=white"/> 
<img  src="https://img.shields.io/badge/node.js-339933?style=flat&logo=Node.js&logoColor=white">
<img src="https://img.shields.io/badge/Figma-00C4B7?style=flat&logo=Figma&logoColor=white"/> 
<img src="https://img.shields.io/badge/styled components-DB7093?style=flat&logo=styled-components&logoColor=white"/> 
<img src="https://img.shields.io/badge/mui-007FFF?style=flat&logo=mui&logoColor=white"/> 
![Recoil](https://img.shields.io/badge/Recoil-ffd966?style=flat&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciICB2aWV3Qm94PSIwIDAgNDggNDgiIHdpZHRoPSIyNDBweCIgaGVpZ2h0PSIyNDBweCI+PHBhdGggZmlsbD0iIzIxMjEyMSIgZD0iTTE4Ljg2OSwyMC45MmMwLjM1Ny0wLjA3NSwwLjcyNC0wLjEyOCwxLjA5MS0wLjE2bDAsMGwwLDBsMi44NTMtMC4yNzFsLTMuODc1LTQuMjQ4IGMtMS4xNjYtMS4yODMtMS44MS0yLjk0NC0xLjgxLTQuNjc5aC0zLjIwNWMwLDIuNTM0LDAuOTQyLDQuOTY3LDIuNjUxLDYuODRMMTguODY5LDIwLjkyeiIvPjxwYXRoIGZpbGw9IiMyMTIxMjEiIGQ9Ik0yOC44NzcsMjcuMTQzYy0wLjI4NywwLjA1My0wLjU4LDAuMDktMC44NzMsMC4xMjJsMCwwbDAsMGwtMy4wODgsMC4yOTNsMy44NjUsNC4yMzcgYzEuMTY2LDEuMjgzLDEuODEsMi45NDQsMS44MSw0LjY3OWgzLjIxYzAtMi41MzQtMC45NDItNC45NjEtMi42NTEtNi44NEwyOC44NzcsMjcuMTQzeiIvPjxwYXRoIGZpbGw9IiMyMTIxMjEiIGQ9Ik0zNC4xODQsMTcuNzI3Yy0wLjUyNy0yLjYxOS0yLjU4Mi00LjUyNS01LjIzMy00Ljg2bC0wLjQ5LTAuMDY0IGMtMS42NTYtMC4yMDgtMi45MDctMS42MjQtMi45MDctMy4yOVY3LjgwNGMxLjQ2OS0wLjYxMiwyLjUwMi0yLjA2LDIuNTAyLTMuNzQ4QzI4LjA1NywxLjgxNSwyNi4yNDIsMCwyNC4wMDEsMCBzLTQuMDU2LDEuODE1LTQuMDU2LDQuMDU2YzAsMS42NSwwLjk5LDMuMDcyLDIuNDA2LDMuNzA1djEuNzUxYzAsMy4yODQsMi40NTQsNi4wNjksNS43MTIsNi40NzNsMC40OSwwLjA2NCBjMS41MjgsMC4xOTIsMi4yODksMS4zMiwyLjQ5MSwyLjMxcy0wLjA1OSwyLjMyNi0xLjM5NSwzLjA5OGMtMC42NTUsMC4zNzgtMS4zNjMsMC42MDctMi4xMTMsMC42NzZsLTcuMzYyLDAuNjkyIGMtMS4yMTQsMC4xMTctMi4zNjQsMC40ODQtMy40MTgsMS4wOTFjLTIuMzE2LDEuMzQxLTMuNDcxLDMuODk3LTIuOTM4LDYuNTE2YzAuNTI3LDIuNjE5LDIuNTgyLDQuNTI1LDUuMjMzLDQuODZsMC40OSwwLjA2NCBjMS42NTYsMC4yMDgsMi45MDcsMS42MjQsMi45MDcsMy4yOXYxLjU1NGMtMS40NjQsMC42MTItMi40OTEsMi4wNi0yLjQ5MSwzLjc0MmMwLDIuMjQxLDEuODE1LDQuMDU2LDQuMDU2LDQuMDU2IHM0LjA1Ni0xLjgxNSw0LjA1Ni00LjA1NmMwLTEuNjU2LTAuOTk1LTMuMDgyLTIuNDE3LTMuNzF2LTEuNTg2YzAtMy4yODQtMi40NTQtNi4wNjktNS43MTItNi40NzNsLTAuNDktMC4wNjQgYy0xLjUyOC0wLjE5Mi0yLjI4OS0xLjMyLTIuNDkxLTIuMzFjLTAuMjAyLTAuOTksMC4wNTktMi4zMjYsMS4zOTUtMy4wOThjMC42NTUtMC4zNzgsMS4zNjMtMC42MDcsMi4xMTMtMC42NzZsNy4zNjItMC42OTIgYzEuMjE0LTAuMTE3LDIuMzY0LTAuNDg0LDMuNDE4LTEuMDkxQzMzLjU2MiwyMi45MDEsMzQuNzExLDIwLjM0NiwzNC4xODQsMTcuNzI3eiIvPjwvc3ZnPg==)

:blue_heart: **Back End**
![Java](https://img.shields.io/badge/Java-f0f0ff?style=flat&logo=data:image/svg+xml;base64,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) <img src="https://img.shields.io/badge/Spring-6DB33F?style=flat&logo=Spring&logoColor=white"/> <img src="https://img.shields.io/badge/Spring Boot-6DB33F?style=flat&logo=Spring Boot&logoColor=white"/> ![JPA](https://img.shields.io/badge/JPA-696969?style=flat&logo=data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Uploaded to: SVG Repo, www.svgrepo.com, Generator: SVG Repo Mixer Tools -->
<svg fill="#000000" width="800px" height="800px" viewBox="0 -8 48 48" version="1.1" xmlns="http://www.w3.org/2000/svg">
<title>jpa</title>
<path d="M5.063 13.531c-0.094 0-0.125-0.031-0.188-0.063-0.031-0.063-0.031-0.125-0.031-0.219s0-0.188 0.031-0.219c0.063-0.063 0.094-0.094 0.188-0.094 0.063 0 0.125 0.031 0.156 0.094 0.031 0.031 0.063 0.125 0.063 0.219s-0.031 0.156-0.063 0.219c-0.031 0.031-0.094 0.063-0.156 0.063zM8.406 9.969c-0.031 0-0.094 0-0.125-0.031-0.063-0.031-0.094-0.125-0.094-0.219 0-0.063 0.031-0.125 0.031-0.188 0.031-0.063 0.094-0.125 0.188-0.125s0.125 0.031 0.156 0.094 0.063 0.125 0.063 0.188-0.031 0.156-0.063 0.219-0.094 0.063-0.156 0.063zM7.313 13.563c-0.031 0-0.063 0-0.094-0.031 0 0-0.031-0.031-0.031-0.094 0-0.031 0.031-0.063 0.063-0.094s0.063-0.031 0.125-0.031l0.063-0.031h0.063l0.031-0.031v0.094c0 0.094-0.031 0.156-0.063 0.188s-0.094 0.031-0.156 0.031zM2.281 13.219h-0.344l0.156-0.5zM7.406 9.75h0.031c0.031 0 0.063-0.031 0.094-0.031h0.031v0.063c0 0.094-0.031 0.156-0.063 0.188-0.063 0.031-0.094 0.031-0.156 0.031h-0.094c0-0.031-0.031-0.063-0.031-0.094 0-0.063 0.031-0.094 0.063-0.125 0.031 0 0.063-0.031 0.125-0.031zM8.5 11.219c-0.031 0.031-0.063 0.031-0.125 0.031h-0.25v-0.375h0.25c0.063 0 0.094 0.031 0.125 0.063 0.063 0 0.063 0.063 0.063 0.125s0 0.125-0.063 0.156zM9.344 11.188c0.063 0 0.094 0 0.156 0.031 0.031 0.031 0.063 0.094 0.063 0.156h-0.438c0-0.063 0.031-0.125 0.063-0.156s0.094-0.031 0.156-0.031zM9.344 12.938c0.063 0 0.125 0.031 0.156 0.094 0.031 0.031 0.063 0.125 0.063 0.219s-0.031 0.156-0.063 0.219c-0.031 0.031-0.094 0.063-0.156 0.063-0.094 0-0.156-0.031-0.188-0.063-0.031-0.063-0.063-0.125-0.063-0.219s0.031-0.188 0.063-0.219c0.031-0.063 0.094-0.094 0.188-0.094zM11.688 8.656h27.125c5.281 0 9.531 3.75 9.531 8.344v10.156h-35.063c-5.25 0-9.531-3.719-9.531-8.313v-3.063c-2.188-0.813-3.75-2.75-3.75-5.031 0-3.031 2.719-5.469 6.063-5.469 2.563 0 4.719 1.406 5.625 3.375zM10.156 9.219h-0.219v0.938h0.25v-0.656c0.031-0.063 0.094-0.094 0.188-0.094 0.063 0 0.094 0.031 0.125 0.063s0.031 0.063 0.031 0.125v0.563h0.25v-0.625c0-0.125-0.031-0.219-0.094-0.25-0.063-0.063-0.156-0.094-0.25-0.094-0.063 0-0.125 0.031-0.188 0.063l-0.094 0.094v-0.125zM10.5 13.031c0.031 0.031 0.031 0.063 0.031 0.094v0.594h0.25v-0.656c0-0.094-0.031-0.188-0.094-0.25-0.063-0.031-0.156-0.063-0.25-0.063-0.063 0-0.125 0-0.188 0.063-0.031 0-0.063 0.063-0.094 0.094v-0.125h-0.219v0.938h0.25v-0.656c0.031-0.063 0.094-0.125 0.188-0.125 0.063 0 0.094 0.031 0.125 0.094zM10.531 10.656v1.281h0.25v-1.281h-0.25zM10.125 11h-0.219v0.938h0.25v-0.438c0-0.094 0-0.156 0.031-0.188 0.031-0.063 0.094-0.094 0.188-0.094h0.063v-0.25h-0.031c-0.063 0-0.125 0.031-0.188 0.063 0 0.031-0.063 0.063-0.094 0.125v-0.156zM9.469 9.406c0.031 0.031 0.063 0.063 0.063 0.094s-0.031 0.063-0.063 0.063-0.063 0.031-0.094 0.031h-0.094c-0.094 0.031-0.156 0.031-0.219 0.063-0.094 0.063-0.125 0.125-0.125 0.25 0 0.094 0.031 0.156 0.094 0.219 0.031 0.031 0.125 0.063 0.188 0.063 0.094 0 0.156 0 0.188-0.031 0.063-0.031 0.094-0.063 0.125-0.094v0.063c0 0 0 0.031 0.031 0.031h0.25v-0.031s-0.031 0-0.031-0.031v-0.594c0-0.125-0.063-0.188-0.125-0.25-0.094-0.031-0.188-0.063-0.281-0.063-0.156 0-0.281 0.063-0.344 0.125-0.031 0.063-0.063 0.125-0.063 0.219h0.25c0-0.031 0-0.063 0.031-0.094 0-0.031 0.063-0.031 0.125-0.031h0.094zM9.219 11.75c-0.063-0.063-0.094-0.125-0.094-0.219h0.688v-0.188c-0.031-0.063-0.031-0.125-0.094-0.188-0.031-0.063-0.094-0.125-0.156-0.156s-0.125-0.031-0.219-0.031c-0.125 0-0.25 0.031-0.344 0.125s-0.125 0.219-0.125 0.375c0 0.188 0.063 0.313 0.156 0.375 0.094 0.094 0.188 0.125 0.313 0.125 0.156 0 0.281-0.031 0.375-0.125l0.094-0.188h-0.25c-0.031 0.031-0.031 0.063-0.063 0.063-0.031 0.031-0.094 0.063-0.125 0.063-0.063 0-0.125-0.031-0.156-0.031zM9.813 13.25c0-0.156-0.031-0.25-0.125-0.375-0.063-0.094-0.188-0.125-0.344-0.125-0.188 0-0.313 0.031-0.375 0.125-0.094 0.125-0.125 0.219-0.125 0.375 0 0.125 0.031 0.25 0.125 0.344 0.063 0.094 0.188 0.156 0.375 0.156 0.156 0 0.281-0.063 0.344-0.156 0.094-0.094 0.125-0.219 0.125-0.344zM8.188 9.219h-0.219v1.313h0.25v-0.5c0 0.063 0.031 0.094 0.063 0.094 0.063 0.031 0.125 0.063 0.188 0.063 0.125 0 0.219-0.031 0.313-0.125 0.063-0.094 0.094-0.219 0.094-0.375s-0.031-0.281-0.125-0.375c-0.063-0.063-0.156-0.125-0.281-0.125-0.063 0-0.125 0.031-0.188 0.063l-0.094 0.094v-0.125zM8.406 10.656h-0.531v1.281h0.25v-0.469h0.281c0.125 0 0.25-0.031 0.313-0.094s0.125-0.156 0.125-0.313c0-0.125-0.063-0.25-0.125-0.313s-0.188-0.094-0.313-0.094zM8.469 12.438v0.219h0.25v-0.219h-0.25zM8.719 13.719v-0.938h-0.25v0.938h0.25zM8.25 13.531c-0.031-0.031-0.031-0.031-0.031-0.094v-0.469h0.156v-0.188h-0.156v-0.281h-0.25v0.281h-0.125v0.188h0.125v0.563c0 0.063 0.031 0.094 0.063 0.125 0.031 0.063 0.094 0.063 0.219 0.063h0.125v-0.188h-0.125zM7.531 9.406c0.031 0.031 0.031 0.063 0.031 0.094s0 0.063-0.063 0.063c0 0-0.031 0.031-0.094 0.031h-0.063c-0.125 0.031-0.188 0.031-0.219 0.063-0.094 0.063-0.156 0.125-0.156 0.25 0 0.094 0.031 0.156 0.094 0.219 0.063 0.031 0.125 0.063 0.219 0.063 0.063 0 0.125 0 0.188-0.031l0.094-0.094c0 0 0 0.031 0.031 0.063v0.031h0.281v-0.031c-0.031 0-0.031 0-0.031-0.031-0.031 0-0.031-0.031-0.031-0.063v-0.531c0-0.125-0.031-0.188-0.125-0.25-0.063-0.031-0.156-0.063-0.281-0.063-0.156 0-0.25 0.063-0.344 0.125-0.031 0.063-0.063 0.125-0.063 0.219h0.25c0-0.031 0-0.063 0.031-0.094s0.063-0.031 0.125-0.031h0.125zM7.094 13.219c-0.094 0.031-0.156 0.125-0.156 0.25 0 0.094 0.031 0.156 0.094 0.188 0.063 0.063 0.125 0.094 0.219 0.094 0.063 0 0.125-0.031 0.188-0.063 0.031-0.031 0.063-0.063 0.125-0.094v0.125h0.281v-0.031l-0.031-0.031c-0.031-0.031-0.031-0.031-0.031-0.063v-0.563c0-0.094-0.031-0.188-0.125-0.219-0.063-0.031-0.156-0.063-0.281-0.063-0.156 0-0.25 0.031-0.313 0.125-0.063 0.063-0.063 0.125-0.094 0.188h0.25c0-0.031 0.031-0.063 0.031-0.063 0.031-0.031 0.063-0.063 0.125-0.063s0.094 0 0.125 0.031c0.031 0 0.031 0.031 0.031 0.094 0 0.031 0 0.031-0.031 0.063h-0.125l-0.063 0.031c-0.094 0-0.188 0.031-0.219 0.063zM6.313 9.688h-0.281v0.031c0 0.125 0.031 0.25 0.094 0.344s0.156 0.125 0.344 0.125c0.156 0 0.25-0.063 0.313-0.156 0.063-0.063 0.063-0.156 0.063-0.25v-0.906h-0.25v0.906c0 0.063-0.031 0.094-0.031 0.125-0.031 0.063-0.063 0.063-0.125 0.063s-0.094 0-0.094-0.063c-0.031-0.031-0.031-0.094-0.031-0.188v-0.031zM6.594 12.438v0.219h0.25v-0.219h-0.25zM6.844 13.719v-0.938h-0.25v0.938h0.25zM5.719 12.875c-0.063 0.094-0.125 0.219-0.125 0.375s0.063 0.281 0.125 0.375c0.063 0.063 0.188 0.125 0.344 0.125 0.125 0 0.25-0.063 0.344-0.156 0.031-0.063 0.063-0.156 0.063-0.219h-0.25c0 0.031-0.031 0.094-0.031 0.125-0.031 0.031-0.063 0.031-0.125 0.031-0.094 0-0.156-0.031-0.188-0.125v-0.313c0.031-0.094 0.094-0.125 0.188-0.125 0.063 0 0.094 0 0.125 0.031s0.031 0.063 0.031 0.094h0.25c0-0.125-0.063-0.219-0.125-0.281-0.063-0.031-0.188-0.063-0.281-0.063-0.156 0-0.25 0.031-0.344 0.125zM4.688 12.875c-0.063 0.125-0.125 0.219-0.125 0.375 0 0.125 0.063 0.25 0.125 0.344 0.094 0.094 0.219 0.156 0.375 0.156s0.281-0.063 0.344-0.156c0.094-0.094 0.125-0.219 0.125-0.344 0-0.156-0.031-0.25-0.125-0.375-0.063-0.094-0.188-0.125-0.344-0.125s-0.281 0.031-0.375 0.125zM2.344 13.438l0.063 0.281h0.313l-0.469-1.281h-0.281l-0.469 1.281h0.281l0.094-0.281h0.469zM3.5 13.656c0.063-0.063 0.094-0.125 0.094-0.219s-0.031-0.125-0.063-0.188c-0.063-0.031-0.125-0.094-0.219-0.094-0.156-0.031-0.25-0.063-0.281-0.094-0.031 0-0.031-0.031-0.031-0.063 0 0 0-0.031 0.031-0.031 0.031-0.031 0.063-0.031 0.125-0.031s0.094 0 0.125 0.031 0.031 0.063 0.031 0.094h0.25c0-0.125-0.063-0.188-0.125-0.25s-0.156-0.063-0.281-0.063-0.219 0.031-0.313 0.094c-0.063 0.063-0.094 0.125-0.094 0.219 0 0.063 0.031 0.125 0.063 0.156 0.063 0.063 0.125 0.094 0.25 0.125s0.219 0.063 0.25 0.063 0.031 0.031 0.031 0.063-0.031 0.063-0.031 0.063c-0.031 0.031-0.094 0.031-0.125 0.031-0.094 0-0.156-0.031-0.188-0.063 0 0-0.031-0.031-0.031-0.094h-0.25c0 0.094 0.031 0.188 0.125 0.25 0.063 0.063 0.156 0.094 0.313 0.094s0.25-0.031 0.344-0.094zM4.406 13.656c0.063-0.063 0.125-0.125 0.125-0.219s-0.031-0.125-0.094-0.188c-0.031-0.031-0.125-0.094-0.219-0.094-0.156-0.031-0.219-0.063-0.25-0.094-0.031 0-0.031-0.031-0.031-0.063 0 0 0-0.031 0.031-0.031 0.031-0.031 0.063-0.031 0.094-0.031 0.094 0 0.125 0 0.156 0.031 0 0.031 0.031 0.063 0.031 0.094h0.25c-0.031-0.125-0.063-0.188-0.125-0.25-0.094-0.063-0.188-0.063-0.313-0.063s-0.219 0.031-0.281 0.094-0.094 0.125-0.094 0.219c0 0.063 0.031 0.125 0.063 0.156 0.031 0.063 0.125 0.094 0.219 0.125 0.156 0.031 0.25 0.063 0.25 0.063 0.031 0 0.063 0.031 0.063 0.063s-0.031 0.063-0.063 0.063c-0.031 0.031-0.063 0.031-0.125 0.031s-0.125-0.031-0.156-0.063c-0.031 0-0.031-0.031-0.031-0.094h-0.25c0 0.094 0.031 0.188 0.094 0.25 0.094 0.063 0.188 0.094 0.344 0.094s0.25-0.031 0.313-0.094zM13.281 26.375h34.281v-9.375c0-4.188-3.906-7.563-8.75-7.563h-26.844c0.125 0.406 0.188 0.844 0.188 1.313 0 3-2.719 5.469-6.094 5.469-0.531 0-1.031-0.063-1.531-0.188v2.813c0 4.156 3.938 7.531 8.75 7.531zM9.344 9.75h0.063c0.031 0 0.063-0.031 0.063-0.031h0.063v0.063c0 0.094-0.031 0.156-0.094 0.188-0.031 0.031-0.094 0.031-0.125 0.031h-0.094c-0.031-0.031-0.031-0.063-0.031-0.094 0-0.063 0-0.094 0.063-0.125 0 0 0.063-0.031 0.094-0.031zM36.031 10.75h2.156c4.344 0 7.844 2.906 7.844 6.469v7.938h-2v-7.625c0-2.688-2.844-4.875-6.313-4.875h-1.688v5.188h6v2h-6v5.313h-2v-14.406h2zM14.344 23.25h1.719v-12.5h2v14.406h-4.188c-4.313 0-7.844-2.906-7.844-6.5v-0.688h2.094v0.531c0 2.625 2.781 4.75 6.219 4.75zM22 10.75h4.5c1.781 0 3.344 0.781 4.406 2 0.781 0.938 1.281 2.125 1.281 3.438s-0.5 2.5-1.281 3.438c-1.063 1.219-2.625 2-4.406 2h-2.5v-2h2.75c1.813-0.188 3.219-1.656 3.219-3.438s-1.406-3.25-3.219-3.438h-4.75v12.406h-2v-14.406h2z"></path>
</svg>) <img src="https://img.shields.io/badge/Spring Security-6DB33F?style=flat&logo=Spring Security&logoColor=white"/> <img src="https://img.shields.io/badge/Gradle-02303A?style=flat&logo=Gradle&logoColor=white"/> <img src="https://img.shields.io/badge/MySQL-4479A1?style=flat&logo=MySQL&logoColor=white"/> <img src="https://img.shields.io/badge/Redis-DC382D?style=flat&logo=Redis&logoColor=white"/>

:yellow_heart: **AI**
<img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=Python&logoColor=white"/>
<img src="https://img.shields.io/badge/NumPy-013243?style=flat&logo=NumPy&logoColor=white"/>
<img src="https://img.shields.io/badge/pandas-150458?style=flat&logo=pandas&logoColor=white"/>
<img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=PyTorch&logoColor=white"/>
<img src="https://img.shields.io/badge/OpenAI-412991?style=flat&logo=OpenAI&logoColor=white"/>
<img src="https://img.shields.io/badge/Jupyter-F37626?style=flat&logo=Jupyter&logoColor=white"/>
<img src="https://img.shields.io/badge/Google Colab-F9AB00?style=flat&logo=Google Colab&logoColor=white"/>
<img src="https://img.shields.io/badge/Django-092E20?style=flat&logo=Django&logoColor=white"/>

:green_heart: **CI/CD**
<img src="https://img.shields.io/badge/Linux-FCC624?style=flat&logo=Linux&logoColor=white"/> <img src="https://img.shields.io/badge/Docker-2496ED?style=flat&logo=Docker&logoColor=white"/> <img src="https://img.shields.io/badge/Jenkins-D24939?style=flat&logo=Jenkins&logoColor=white"/> <img src="https://img.shields.io/badge/Amazon EC2-FF9900?style=flat&logo=Amazon EC2&logoColor=white"/>

:purple_heart: **Tools**
<img src="https://img.shields.io/badge/Git-F05032?style=flat&logo=Git&logoColor=white"/> <img src="https://img.shields.io/badge/GitLab-FC6D26?style=flat&logo=GitLab&logoColor=white"/> <img src="https://img.shields.io/badge/Postman-FF6C37?style=flat&logo=Postman&logoColor=white"/> <img src="https://img.shields.io/badge/Jira-0052CC?style=flat&logo=Jira Software&logoColor=white"/> <img src="https://img.shields.io/badge/Notion-000000?style=flat&logo=Notion&logoColor=white"/> <img src="https://img.shields.io/badge/Mattermost-0058CC?style=flat&logo=Mattermost&logoColor=white"/> <img src="https://img.shields.io/badge/Discord-5865F2?style=flat&logo=Discord&logoColor=white"/>

:sparkling_heart: **IDE**
<img src="https://img.shields.io/badge/VS Code-007ACC?style=flat&logo=Visual Studio Code&logoColor=white"/> 
<img src="https://img.shields.io/badge/IntelliJ-000000?style=flat&logo=IntelliJ IDEA&logoColor=white"/>

<br />

### üöÄ Î∞∞Ìè¨ Ï£ºÏÜå

    üîé URL : [https://j8b101.p.ssafy.io/]

<br />

### üé´ ERD

#### ![ERD](https://user-images.githubusercontent.com/109534450/229389722-3c06c51e-9822-40cd-ba7b-cb1b60aaa1da.png)
<br />

### üçè API

#### ![api](https://user-images.githubusercontent.com/109534450/229389453-80caf23c-fae6-403b-b71d-301f4495feb7.PNG)
- [Postman API Ï†ïÎ¶¨](https://documenter.getpostman.com/view/25310566/2s93JxsMqe)

<br />

### üéá ÏÑúÎπÑÏä§ ÏïÑÌÇ§ÌÖçÏ≥ê


<br />

## üìú ÌîÑÎ°úÏ†ùÌä∏ Í≤∞Í≥ºÎ¨º


### ÏïΩÍ¥Ä ÎèôÏùò

<br />

### Î©îÏù∏ ÌéòÏù¥ÏßÄ

<br />

### Îã§Ïù¥Ïñ¥Î¶¨ ÏûëÏÑ± ÌéòÏù¥ÏßÄ

<br />

### Ïõî / Ïùº

<br />

### ÏãúÍ∞ÅÌôî

<br />

### ÌîÑÎ°úÍ∑∏Îû® ÏÑ§Ï†ï

<br />



## üé® FE

Flutter STT
  FlutterÏùò STT(Speech To Text) Ìå®ÌÇ§ÏßÄÎäî ÏùåÏÑ±Ïù∏Ïãù APIÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.

Î™®Î∞îÏùº Ïö¥ÏòÅÏ≤¥Ï†ú(Android, iOS)Ïóê Îî∞ÎùºÏÑú ÏÇ¨Ïö©ÌïòÎäî APIÍ∞Ä Îã§Î¶ÖÎãàÎã§.

- **Android** : Google Speech Recognition API
- **iOS** : Siri Speech Recognition API

Í∏∞Ï°¥Ïùò STTÎäî Î®∏Ïã†Îü¨ÎãùÏù¥ÎÇò Îî• Îü¨Îãù Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌïôÏäµÌïòÍ≥† Î™®Îç∏ÏùÑ Íµ¨Ï∂ïÌïòÏßÄÎßå,

FlutterÏùò STT Ìå®ÌÇ§ÏßÄÎäî ÌîåÎû´ÌèºÎ≥Ñ APIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏùåÏÑ± Ïù∏Ïãù ÏûëÏóÖÏùÑ ÏàòÌñâÌï©ÎãàÎã§ (ÎåÄÍ∑úÎ™® Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú ÏÇ¨Ï†Ñ ÌõàÎ†®ÎêòÎ©∞ ÏùåÏÑ± Î∞è Ïñ∏Ïñ¥ Î™®Îç∏Ïùò Ï°∞Ìï©ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏùåÏÑ±Ïù∏ÏãùÏùÑ ÏàòÌñâ)

**ÏÑ±Îä•** : ÏùºÎ∞òÏ†ÅÏùÄ ÎåÄÌôîÏóêÏÑúÎäî Ï¢ãÏùÄ ÏÑ±Îä•Í≥º Ï†ïÌôïÎèÑÎ•º Ï†úÍ≥µÌïòÏßÄÎßå,

ÌäπÏ†ï ÏÇ¨Ïö© ÏÇ¨Î°ÄÎÇò Ïñ∏Ïñ¥Ïóê ÏµúÏ†ÅÌôîÎêòÏñ¥ ÏûàÏßÄ ÏïäÏäµÎãàÎã§. ex) Ïã∏Ìîº


# üóø AI ü©∫ ÏÇ¨Ïö© Î™®Îç∏ : KoBERT / KoGPT2
---

## üõπ KoBERT ?

- Bert Î™®Îç∏Ïùò ÌïúÍµ≠Ïñ¥ Î≤ÑÏ†ÑÏúºÎ°ú, SKTÏóêÏÑú  Íµ¨Í∏ÄÏùò BERT Î™®Îç∏ÏùÑ Î∞îÌÉïÏúºÎ°ú Í∞úÎ∞úÌïòÏòÄÏäµÎãàÎã§. 

- ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨(NLP)Í∞Ä Í∞ÄÎä•Ìïú ÏÇ¨Ï†Ñ ÌïôÏäµÎêú Ïñ∏Ïñ¥ Î™®Îç∏ÏûÖÎãàÎã§.

- ÌïúÍµ≠Ïñ¥ Î¨∏Ïû• Î∂ÑÎ•ò, Í∞úÏ≤¥Î™Ö Ïù∏Ïãù, Î¨∏Ïû• Ïú†ÏÇ¨ÎèÑÎ•º ÌååÏïÖÌï† Ïàò ÏûàÏäµÎãàÎã§.

- ÎÑ§Ïù¥Î≤ÑÏóêÏÑú Í≥µÍ∞úÌïú ÌïúÍ∏Ä ÏúÑÌÇ§ÌîºÎîîÏïÑ Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ï†Ñ ÌïôÏäµÌïòÏòÄÏäµÎãàÎã§.

- [KoBERT ÍπÉÌóàÎ∏å](https://github.com/SKTBrain/KoBERT)

--- 
## üõ∂ BERT?
- BERTÎäî "Bidirectional Encoder Representations from Transformers"Ïùò ÏïΩÏñ¥Î°ú, Íµ¨Í∏ÄÏóêÏÑú Í∞úÎ∞úÌïú ÏÇ¨Ï†Ñ ÌïôÏäµÎêú Ïñ∏Ïñ¥ Î™®Îç∏ÏûÖÎãàÎã§. 
- BERTÏùò Ïû•Ï†êÏù∏ ÏÇ¨Ï†Ñ ÌïôÏäµÎêú Ïñ∏Ïñ¥ Î™®Îç∏Ïùò ÏßÄÏãùÏùÑ ÌôúÏö©ÌïòÏó¨ Î¨∏Ïû• Î∂ÑÎ•ò, Î¨∏Ïû• Ïú†ÏÇ¨ÎèÑ, ÏßàÎ¨∏ ÏùëÎãµ Îì±Ïùò ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÌÉúÏä§ÌÅ¨Î•º ÏàòÌñâÌï©ÎãàÎã§.
- Ï†ÅÏùÄ ÏñëÏùò Îç∞Ïù¥ÌÑ∞Î°úÎèÑ ÎÜíÏùÄ ÏÑ±Îä•ÏùÑ Î∞úÌúòÌï† Ïàò ÏûàÎäî Ïû•Ï†êÏù¥ ÏûàÏäµÎãàÎã§.

- TransformerÎùºÎäî Î™®Îç∏ Íµ¨Ï°∞Î•º ÏÇ¨Ïö©Ìï©ÎãàÎã§. 
    * TransformerÎäî Attention mechanismÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏûÖÎ†•Îêú Îã®Ïñ¥Îì§ ÏÇ¨Ïù¥Ïùò ÏùòÏ°¥ Í¥ÄÍ≥ÑÎ•º Ï∞æÏïÑÎÇ¥Îäî Î™®Îç∏ÏûÖÎãàÎã§.
- [BERT ÍπÉÌóàÎ∏å](https://github.com/google-research/bert)

---

## üõ´ KoGPT2 ?

- KoGPT2Îäî SKTÏóêÏÑú Í∞úÎ∞úÌïú ÌïúÍµ≠Ïñ¥ ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨Î•º ÏúÑÌïú GPT Î™®Îç∏ÏûÖÎãàÎã§. GPTÎäî Generative Pre-trained TransformerÏùò ÏïΩÏûêÎ°ú, Ìä∏ÎûúÏä§Ìè¨Î®∏(Transformer) Î™®Îç∏ÏùÑ Ïù¥Ïö©ÌïòÏó¨ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±Ïóê ÎåÄÌïú ÌïôÏäµÏùÑ ÏàòÌñâÌï©ÎãàÎã§.

- KoGPT2Îäî ÌïúÍµ≠Ïñ¥ Î¨∏Ïû•Ïóê ÎåÄÌïú ÌÜ†ÌÅ∞Ìôî(tokenization), ÏûÑÎ≤†Îî©(embedding), GPT Î™®Îç∏ ÌïôÏäµ Î∞è ÌÖçÏä§Ìä∏ ÏÉùÏÑ±ÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÎäî Î™®ÎìàÎì§ÏùÑ Ï†úÍ≥µÌï©ÎãàÎã§. Ïù¥Î•º Ïù¥Ïö©ÌïòÏó¨ Îã§ÏñëÌïú ÌïúÍµ≠Ïñ¥ ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÌÉúÏä§ÌÅ¨Ïóê ÌôúÏö©Ìï† Ïàò ÏûàÏäµÎãàÎã§. 
- KoGPT2Î•º Ïù¥Ïö©ÌïòÏó¨ ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÌÉúÏä§ÌÅ¨Î•º ÏàòÌñâÌïòÎ†§Î©¥, Î®ºÏ†Ä Î¨∏Ïû•ÏùÑ ÌÜ†ÌÅ∞ÌôîÌïòÍ≥† KoGPT Î™®Îç∏Ïóê ÏûÖÎ†•ÏúºÎ°ú ÎÑ£Ïñ¥ ÏòàÏ∏°Í∞íÏùÑ ÏñªÏùÑ Ïàò ÏûàÏäµÎãàÎã§. Ïù¥ÌõÑ, ÏñªÏùÄ ÏòàÏ∏°Í∞íÏùÑ Ïù¥Ïö©ÌïòÏó¨ Îã§ÏñëÌïú ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÌÉúÏä§ÌÅ¨Î•º ÏàòÌñâÌï† Ïàò ÏûàÏäµÎãàÎã§.

---
## üí° **Í∞êÏ†ï Î∂ÑÏÑù üëâ KoBERT**

### ‚úèÔ∏è **Process**

1. **ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï†Ñ Ï≤òÎ¶¨**
    - ÏûÖÎ†• Î¨∏Ïû•ÏùÑ ÌÜ†ÌÅ∞ÌôîÌïòÏó¨ ÌÜ†ÌÅ∞ IDÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.
    Î¨∏Ïû•Ïùò Ïã§Ï†ú Í∏∏Ïù¥Î•º ÎÇòÌÉÄÎÇ¥Îäî ÎßàÏä§ÌÅ¨Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
    Î¨∏Ïû• ÏåçÏùò Í≤ΩÏö∞, Î¨∏Ïû• Í∞Ñ Íµ¨Î∂ÑÏùÑ ÎÇòÌÉÄÎÇ¥Îäî ÏÑ∏Í∑∏Î®ºÌä∏ IDÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
2. **BERT Î™®Îç∏ Ï†ÅÏö©**
    - Ï†ÑÏ≤òÎ¶¨Îêú ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º BERT Î™®Îç∏Ïóê ÏûÖÎ†•ÌïòÏó¨ Ï∂úÎ†•Í∞íÏùÑ ÏñªÏäµÎãàÎã§.
    - BERT Î™®Îç∏ÏùÄ ÏûÖÎ†• ÌÜ†ÌÅ∞ÏùÑ ÏûÑÎ≤†Îî©ÌïòÍ≥†, Ïñ¥ÌÖêÏÖò Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Í∞Å ÌÜ†ÌÅ∞Ïùò ÏùòÎØ∏Î•º ÌååÏïÖÌï©ÎãàÎã§.
    - Ï∂úÎ†•Í∞íÏùÄ BERTÏùò Ï∂úÎ†• Ï∞®Ïõê ÌÅ¨Í∏∞Ïù∏ 768Ï∞®ÏõêÏúºÎ°ú ÎÇòÏòµÎãàÎã§.
3. **Ï∂úÎ†•Í∞í Î≥ÄÌôò**
    - BERT Î™®Îç∏Ïùò Ï∂úÎ†•Í∞í Ï§ë Î¨∏Ïû•ÏùÑ ÎåÄÌëúÌïòÎäî poolerÎ•º ÏÇ¨Ïö©ÌïòÏó¨ 768Ï∞®Ïõê Î≤°ÌÑ∞Î•º ÏñªÏäµÎãàÎã§.
    - Î≤°ÌÑ∞Î•º ÏÑ†Ìòï Î†àÏù¥Ïñ¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÌÅ¥ÎûòÏä§ Î†àÏù¥Î∏îÏóê ÎåÄÌïú Î°úÏßìÏúºÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.
    - Î°úÏßìÏùÄ Í∞Å ÌÅ¥ÎûòÏä§Ïóê ÎåÄÌïú Ï†êÏàòÎ•º ÏùòÎØ∏Ìï©ÎãàÎã§.
4. **ÏÜêÏã§ Ìï®Ïàò Î∞è ÏµúÏ†ÅÌôî**
    - logitÍ≥º Ïã§Ï†ú ÌÅ¥ÎûòÏä§ Î†àÏù¥Î∏î Í∞ÑÏùò Ï∞®Ïù¥Î•º Ï∏°Ï†ïÌïòÎäî ÍµêÏ∞® ÏóîÌä∏Î°úÌîº ÏÜêÏã§ Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌïôÏäµÌï©ÎãàÎã§.
    - ÌïôÏäµÏóêÎäî ÌôïÎ•†Ï†Å Í≤ΩÏÇ¨ ÌïòÍ∞ïÎ≤ï(Stochastic Gradient Descent)Ïùò Î≥ÄÌòï Ï§ë ÌïòÎÇòÏù∏ AdamW ÏòµÌã∞ÎßàÏù¥Ï†ÄÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.
    - ÌïôÏäµÎ•†Í≥º ÌïôÏäµ Ïä§ÏºÄÏ§ÑÎßÅ Îì±ÏùÑ Ï°∞Ï†ïÌïòÏó¨ ÌïôÏäµÏùÑ ÏßÑÌñâÌï©ÎãàÎã§.

### üßæ Dataset
- [AI Hub Í∞êÏÑ± ÎåÄÌôî ÎßêÎ≠âÏπò Îç∞Ïù¥ÌÑ∞ ÏÖã](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=86)
- Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Î∞è ÌïôÏäµ

### üõ† Requirements

```
!pip install gluonnlp pandas tqdm
!pip install mxnet
!pip install sentencepiece
!pip install transformers
!pip install torch
!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'

```

### ‚öæÔ∏è Import

```
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import gluonnlp as nlp
import numpy as np
from tqdm import tqdm, tqdm_notebook
import pandas as pd
from sklearn.model_selection import train_test_split
from kobert_tokenizer import KoBERTTokenizer
from transformers import BertModel
from transformers import AdamW
from transformers.optimization import get_cosine_schedule_with_warmup

from google.colab import drive
drive.mount('/content/drive')

```

- **torch**
- **nn, optim, F, Dataset, DataLoader :** ÌååÏù¥ÌÜ†Ïπò ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò ÌïòÏúÑ Î™®Îìà, Ïã†Í≤ΩÎßù Î™®Îç∏, ÏµúÏ†ÅÌôî ÏïåÍ≥†Î¶¨Ï¶ò, Ìï®Ïàò, Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è Îç∞Ïù¥ÌÑ∞ Î°úÎçî
- **gluonnlp :** MXNet ÌîÑÎ†àÏûÑ ÏõåÌÅ¨ÏóêÏÑú ÏÇ¨Ïö©ÎêòÎäî ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ ÎùºÏù¥Î∏åÎü¨Î¶¨
- **numpy :** Îã§Ï∞®Ïõê ÌñâÎ†¨ Í¥ÄÎ†®
- **pandas :** Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
- **KoBERTTokenizer :** KoBERTÏùò ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä
- **BertModel**
- **AdamW :** AdamW ÏµúÏ†ÅÌôî
- **get_cosine_schedule_with_warmup :** learning rate Ïä§ÏºÄÏ§ÑÎßÅ Ï†ÅÏö© Ìï®Ïàò
- **drive.mount('/content/drive/') :** Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÎ•º ColabÏóê ÎèôÍ∏∞Ìôî
- **device = torch.device("cuda:0") :** GPU ÏÇ¨Ïö©

### üéæ Hyper Parameter

```
# Setting parameters
max_len = 64
batch_size = 64
warmup_ratio = 0.1
num_epochs = 50
max_grad_norm = 1
log_interval = 200
learning_rate =  5e-5
```

***ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÏÖãÌåÖ***

- **max_len** Î¨∏Ïû• ÏµúÎåÄ Í∏∏Ïù¥
- **batch_size** Ìïú Î≤àÏùò batchÎßàÎã§ Ï£ºÎäî Îç∞Ïù¥ÌÑ∞ ÏÉòÌîåÏùò size. 
- **num_epochs :** Ï†ÑÏ≤¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌïôÏäµ ÌöüÏàò
- **learning_rate :** ÌïôÏäµÎ•†

### üßö‚Äç‚ôÄÔ∏è BERT Dataset

```
class BERTDataset(Dataset):
    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,
                 pad, pair):

        transform = nlp.data.BERTSentenceTransform(
            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)

        self.sentences = [transform([i[sent_idx]]) for i in dataset]
        self.labels = [np.int32(i[label_idx]) for i in dataset]

    def __getitem__(self, i):
        return (self.sentences[i] + (self.labels[i], ))

    def __len__(self):
        return (len(self.labels))
```

- gluonnlpÏùò BERTSentenceTransformÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏûÖÎ†• Î¨∏Ïû•ÏùÑ BERT ÏûÖÎ†• ÌòïÏãùÏóê ÎßûÍ≤å Î≥ÄÌôòÌï©ÎãàÎã§.
-transform Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Í∞Å Î¨∏Ïû•ÏùÑ BERT ÏûÖÎ†• ÌòïÏãùÏóê ÎßûÍ≤å Î≥ÄÌôò

### üßö‚Äç‚ôÇÔ∏è BERT Classifier

```
class BERTClassifier(nn.Module):
    def __init__(self,
                 bert,
                 hidden_size = 768,
                 num_classes=6,
                 dr_rate=None,
                 params=None):
        super(BERTClassifier, self).__init__()
        self.bert = bert
        self.dr_rate = dr_rate

        self.classifier = nn.Linear(hidden_size , num_classes)
        if dr_rate:
            self.dropout = nn.Dropout(p=dr_rate)

    def gen_attention_mask(self, token_ids, valid_length):
        attention_mask = torch.zeros_like(token_ids)
        for i, v in enumerate(valid_length):
            attention_mask[i][:v] = 1
        return attention_mask.float()

    def forward(self, token_ids, valid_length, segment_ids):
        attention_mask = self.gen_attention_mask(token_ids, valid_length)

        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))
        if self.dr_rate:
            out = self.dropout(pooler)
        return self.classifier(out)

```

- ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Ïùò Ìå®Îî© Î∂ÄÎ∂ÑÏùÑ Ï†úÏô∏ÌïòÍ≥†, Ïã§Ï†ú ÏûÖÎ†•Ïóê ÎåÄÌïú Ïñ¥ÌÖêÏÖò ÎßàÏä§ÌÅ¨Î•º ÏÉùÏÑ±ÌïòÎäî Ìï®ÏàòÏûÖÎãàÎã§.
- token_idsÎäî ÏûÖÎ†• Î¨∏Ïû•ÏùÑ ÌÜ†ÌÅ∞ÌôîÌïú Í≤∞Í≥º
- gen_attention_mask Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïñ¥ÌÖêÏÖò ÎßàÏä§ÌÅ¨Î•º ÏÉùÏÑ±
- BERT Î™®Îç∏Ïóê ÏûÖÎ†•ÏùÑ Ï†ÑÎã¨ÌïòÏó¨ Ï∂úÎ†•ÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§.

### üî´ ÌÜ†ÌÅ¨ ÎÇòÏù¥Ï†Ä / Î™®Îç∏ Ï†ïÏùò

```
tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')
bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)
vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')
tok = tokenizer.tokenize
```

- skt/kobert-base-v1 Î™®Îç∏Ïùò **ÏÇ¨Ï†Ñ ÌïôÏäµÎêú Í∞ÄÏ§ëÏπò** Î°úÎìú
- BERTVocab Í∞ùÏ≤¥Ïóê tokenizer.vocab_file ÏÇ¨Ï†Ñ(vocab) Î°úÎìú

### üíø Îç∞Ïù¥ÌÑ∞ Î°úÎìú/ Ï†ÑÏ≤òÎ¶¨

```
train_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/·ÑÄ·Ö°·Ü∑·Ñå·Ö•·Üº·Ñá·ÖÆ·Ü´·Ñâ·Ö•·Ü®dataset.csv', encoding='cp949')
validation_set = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Í∞êÏÑ±ÎåÄÌôîÎßêÎ≠âÏπò(ÏµúÏ¢ÖÎç∞Ïù¥ÌÑ∞)_Validation.csv',encoding='cp949')
train_set = train_set.loc[:, ['sentiment', 'user']]
validation_set = validation_set.loc[:, ['Í∞êÏ†ï_ÎåÄÎ∂ÑÎ•ò', 'ÏÇ¨ÎûåÎ¨∏Ïû•1']]

train_set.dropna(inplace=True)
validation_set.dropna(inplace=True)
train_set.columns = ['label', 'data']
validation_set.columns = ['label', 'data']

train_set.loc[(train_set['label'] == 'ÏùºÏÉÅ'), 'label'] = 0
train_set.loc[(train_set['label'] == 'Î∂ÑÎÖ∏'), 'label'] = 1
train_set.loc[(train_set['label'] == 'Î∂àÏïà'), 'label'] = 2
train_set.loc[(train_set['label'] == 'Ïä¨Ìîî'), 'label'] = 3
train_set.loc[(train_set['label'] == 'Í∏∞ÏÅ®'), 'label'] = 4
train_set.loc[(train_set['label'] == 'Ïö∞Ïö∏'), 'label'] = 5

validation_set.loc[(validation_set['label'] == 'ÏùºÏÉÅ'), 'label'] = 0
validation_set.loc[(validation_set['label'] == 'Î∂ÑÎÖ∏'), 'label'] = 1
validation_set.loc[(validation_set['label'] == 'Î∂àÏïà'), 'label'] = 2
validation_set.loc[(validation_set['label'] == 'Ïä¨Ìîî'), 'label'] = 3
validation_set.loc[(validation_set['label'] == 'Í∏∞ÏÅ®'), 'label'] = 4
validation_set.loc[(validation_set['label'] == 'Ïö∞Ïö∏'), 'label'] = 5

train_set_data = [[i, str(j)] for i, j in zip(train_set['data'], train_set['label'])]

# validation_set_data = [[i, str(j)] for i, j in zip(validation_set['data'], validation_set['label'])]

train_set_data, test_set_data = train_test_split(train_set_data, test_size = 0.2, random_state=4)
train_set_data = BERTDataset(train_set_data, 0, 1, tok, vocab, max_len, True, False)
test_set_data = BERTDataset(test_set_data, 0, 1, tok, vocab, max_len, True, False)
train_dataloader = torch.utils.data.DataLoader(train_set_data, batch_size=batch_size, num_workers=2)
test_dataloader = torch.utils.data.DataLoader(test_set_data, batch_size=batch_size, num_workers=2)

```

### üß∏ Î™®Îç∏ ÌïôÏäµ

```
model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)
# Prepare optimizer and schedule (linear warmup and decay)
no_decay = ['bias', 'LayerNorm.weight']
optimizer_grouped_parameters = [
    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},
    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}
]
optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)
loss_fn = nn.CrossEntropyLoss()
t_total = len(train_dataloader) * num_epochs
warmup_step = int(t_total * warmup_ratio)
scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)

for e in range(num_epochs):
    train_acc = 0.0
    test_acc = 0.0
    model.train()
    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):
        optimizer.zero_grad()
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        loss = loss_fn(out, label)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()
        scheduler.step()  # Update learning rate schedule
        train_acc += calc_accuracy(out, label)
        if batch_id % log_interval == 0:
            print("epoch {} batch id {} loss {} train acc {}".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))
    print("epoch {} train acc {}".format(e+1, train_acc / (batch_id+1)))
    model.eval()
    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        test_acc += calc_accuracy(out, label)
    print("epoch {} test acc {}".format(e+1, test_acc / (batch_id+1)))

```

**train Í≥º validation ÏßÑÌñâ**

### **ÌïôÏäµ ÏÑ§Ï†ïÍ∞í**

- BERTClassifier ÌÅ¥ÎûòÏä§Î•º ÏÇ¨Ïö©ÌïòÏó¨ Î™®Îç∏ Í∞ùÏ≤¥Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
- Î™®Îç∏ÏùÄ BERT Î™®Îç∏Í≥º ÌÅ¥ÎûòÏä§ Î∂ÑÎ•òÎ•º ÏúÑÌïú ÏÑ†Ìòï Î†àÏù¥Ïñ¥Î°ú Íµ¨ÏÑ±
- AdamW ÏòµÌã∞ÎßàÏù¥Ï†ÄÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌïôÏäµÏùÑ ÏßÑÌñâÌï©ÎãàÎã§.
- Í∞ÄÏ§ëÏπò Í∞êÏá†(weight decay)Î•º Ï†ÅÏö©ÌïòÏó¨ Í≥ºÏ†ÅÌï©ÏùÑ Î∞©ÏßÄÌï©ÎãàÎã§.
- Í∞ÄÏ§ëÏπò Í∞êÏá†Î•º Ï†ÅÏö©ÌïòÏßÄ ÏïäÎäî ÌååÎùºÎØ∏ÌÑ∞ÏôÄ Ï†ÅÏö©ÌïòÎäî ÌååÎùºÎØ∏ÌÑ∞Î•º Íµ¨Î∂ÑÌïòÏó¨ ÏòµÌã∞ÎßàÏù¥Ï†ÄÎ•º ÏÑ§Ï†ï
- CrossEntropyLoss Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏÜêÏã§Í∞íÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§.

### **ÌïôÏäµ ÎèôÏûëÍ≥ºÏ†ï (for ~)**

- Î™®Îç∏ÏùÑ ÌïôÏäµ Î™®ÎìúÎ°ú Î≥ÄÍ≤ΩÌï©ÎãàÎã§.
- token_ids, segment_ids, valid_length, label Í∞íÏùÑ GPU Ïò¨Î¶¨Í≥†, modelÏóê input -> out
- out Í∞íÍ≥º label Í∞íÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Cross Entropy LossÎ•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§.
- loss.backward() Ìï®ÏàòÎ•º Ìò∏Ï∂úÌï¥ Î™®Îç∏Ïùò Í∞Å ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎåÄÌïú Í∑∏ÎûòÎîîÏñ∏Ìä∏Î•º Í≥ÑÏÇ∞
- optimizer.step() Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ Í∑∏ÎûòÎîîÏñ∏Ìä∏ Í∞íÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌååÎùºÎØ∏ÌÑ∞Î•º ÏóÖÎç∞Ïù¥Ìä∏
- CosineAnnealingWarmRestarts Ïä§ÏºÄÏ§ÑÎü¨ ÏÇ¨Ïö©, ÌïôÏäµÎ•†ÏùÑ Ï°∞Ï†ï
- ÌòÑÏû¨ Î∞∞ÏπòÏùò ÌïôÏäµ Ï†ïÌôïÎèÑ train_accÏóê ÎàÑÏ†Å
- ÌòÑÏû¨ epochÏùò ÌïôÏäµ Ï†ïÌôïÎèÑÎ•º Ï∂úÎ†•

### **üß¨ Í∞êÏ†ï**
**üòÄÏùºÏÉÅ - 0 üòäÍ∏∞ÏÅ® -1 üòßÎ∂àÏïà - 2 üò≠Ïä¨Ìîî - 3 üò°Î∂ÑÎÖ∏ - 4 üò•Ïö∞Ïö∏ - 5**

<img src = "https://user-images.githubusercontent.com/109534450/229018209-f9fb7af0-0800-47f8-981b-3ea3e13d2e9d.png" width="55%" height="55%">


### üì§ Predict

```
def calc_accuracy(X,Y):
    max_vals, max_indices = torch.max(X, 1)
    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]
    return train_acc
def predict(sentence):
    dataset = [[sentence, '0']]
    test = BERTDataset(dataset, 0, 1, tok, vocab, max_len, True, False)
    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=2)
    model.eval()
    answer = 0
    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        for logits in out:
            logits = logits.detach().cpu().numpy()
            answer = np.argmax(logits)
    return answer
```

- predict Ìï®ÏàòÎäî ÏûÖÎ†• Î¨∏Ïû•ÏùÑ ÏûÖÎ†• Î∞õÏïÑ Ìï¥Îãπ Î¨∏Ïû• Í∞êÏ†ï ÏòàÏ∏°ÌïòÎäî Ìï®Ïàò
- ÏûÖÎ†• Î¨∏Ïû•ÏùÑ datasetÏóê Ï∂îÍ∞ÄÌïòÏó¨ BERTDataset Í∞ùÏ≤¥Î•º ÏÉùÏÑ±
- Î™®Îç∏ ÌèâÍ∞Ä Î™®Îìú(model.eval())
- DataLoaderÏóêÏÑú Î∞∞Ïπò Îã®ÏúÑÎ°ú ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏ÏôÄ Î™®Îç∏Ïóê ÏûÖÎ†•ÌïòÏó¨ ÏòàÏ∏° Í∞íÏùÑ ÏñªÏäµÎãàÎã§.
- Î™®Îç∏ Ï∂úÎ†• Í∞íÏóêÏÑú Í∞ÄÏû• ÌÅ∞ Í∞íÏóê Ìï¥ÎãπÌïòÎäî Ïù∏Îç±Ïä§Î•º ÏòàÏ∏° Í∞íÏúºÎ°ú Î∞òÌôò

### üì© **OUT**
<img src = "https://user-images.githubusercontent.com/109534450/229065068-57d1e4f1-b9f1-461c-a0d2-d8a1d966d20f.png" width="55%" height="55%">

### ‚ú® Í≤∞Í≥ºÎ¨º
**Loss**
- CrossEntropyLoss() - ÍµêÏ∞® ÏóîÌä∏Î°úÌîº Ïò§Ï∞®
- <img src = "https://user-images.githubusercontent.com/109534450/229016538-98df19eb-1bd3-4f78-8aff-abf498ca8759.png" width="35%" height="35%">
- Îëê¬†ÌôïÎ•†¬†Î∂ÑÌè¨Ïùò¬†Ï∞®Ïù¥Î•º¬†Íµ¨ÌïòÍ∏∞¬†ÏúÑÌï¥ÏÑú¬†ÏÇ¨Ïö©Îê©ÎãàÎã§.
- Ïã§Ï†ú¬†Îç∞Ïù¥ÌÑ∞Ïùò¬†ÌôïÎ•†¬†Î∂ÑÌè¨ÏôÄ, ÌïôÏäµÎêú Î™®Îç∏Ïù¥¬†Í≥ÑÏÇ∞Ìïú ÌôïÎ•† Î∂ÑÌè¨Ïùò Ï∞®Ïù¥Î•º Íµ¨ÌïòÎäîÎç∞ ÏÇ¨Ïö©ÎêúÎã§.

<img src = "https://user-images.githubusercontent.com/109534450/229390889-8b9a2114-675f-4529-aacf-29a2fbd19055.png" width="55%" height="55%">



**Accuracy**


<img src = "https://user-images.githubusercontent.com/109534450/229020020-d61be612-8721-4348-9961-390a18955766.png" width="55%" height="55%">

---
## üí° **Í∞êÏÑ± Ï±óÎ¥á üëâ KoGPT2**
### ‚úèÔ∏è **Process**

1. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨

- ÎåÄÌôî Î¨∏Ïû•ÏùÑ ÌÜ†ÌÅ∞ÌôîÌïòÏó¨ ÌÜ†ÌÅ∞ IDÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§.
ÏßàÎ¨∏Í≥º ÎåÄÎãµ Í∞Ñ Íµ¨Î∂ÑÏùÑ ÎÇòÌÉÄÎÇ¥Îäî ÌÜ†ÌÅ∞ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§.
Î¨∏Ïû• ÏåçÏùò Í≤ΩÏö∞, Î¨∏Ïû• Í∞Ñ Íµ¨Î∂ÑÏùÑ ÎÇòÌÉÄÎÇ¥Îäî ÌÜ†ÌÅ∞ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§.
Î¨∏Ïû•Ïùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥ºÌïòÎäî Í≤ΩÏö∞, ÏµúÎåÄ Í∏∏Ïù¥Ïóê ÎßûÍ≤å ÏûòÎùºÎÉÖÎãàÎã§.
2. koGPT Î™®Îç∏ Ï†ÅÏö©

- Ï†ÑÏ≤òÎ¶¨Îêú ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞Î•º KoGPT2 Î™®Îç∏Ïóê ÏûÖÎ†•ÌïòÏó¨ Ï∂úÎ†•Í∞íÏùÑ ÏñªÏäµÎãàÎã§.
KoGPT2 Î™®Îç∏ÏùÄ ÏûÖÎ†• ÌÜ†ÌÅ∞ÏùÑ ÏûÑÎ≤†Îî©ÌïòÍ≥†, Ïñ¥ÌÖêÏÖò Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Í∞Å ÌÜ†ÌÅ∞Ïùò ÏùòÎØ∏Î•º ÌååÏïÖÌï©ÎãàÎã§.
Ï∂úÎ†•Í∞íÏùÄ KoGPT2 Î™®Îç∏Ïùò Ï∂úÎ†• Ï∞®Ïõê ÌÅ¨Í∏∞ÏôÄ ÎèôÏùºÌïú ÌÅ¨Í∏∞Ïùò Î°úÏßìÏúºÎ°ú ÎÇòÏòµÎãàÎã§.
3. ÏÜêÏã§ Ìï®Ïàò Î∞è ÏµúÏ†ÅÌôî

- logitÍ≥º Ïã§Ï†ú Î†àÏù¥Î∏î Í∞ÑÏùò Ï∞®Ïù¥Î•º Ï∏°Ï†ïÌïòÎäî ÍµêÏ∞® ÏóîÌä∏Î°úÌîº ÏÜêÏã§ Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌïôÏäµÌï©ÎãàÎã§.
ÌïôÏäµÏóêÎäî Adam ÏòµÌã∞ÎßàÏù¥Ï†ÄÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.
ÌïôÏäµÎ•†Í≥º ÌïôÏäµ Ïä§ÏºÄÏ§ÑÎßÅ Îì±ÏùÑ Ï°∞Ï†ïÌïòÏó¨ ÌïôÏäµÏùÑ ÏßÑÌñâÌï©ÎãàÎã§.
4. Predict

- KoGPT2 Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏûÖÎ†•Îêú ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎåÄÎãµÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
Ïù∏ÏΩîÎî©Îêú input_idsÎ•º Î™®Îç∏Ïóê ÏûÖÎ†•ÏúºÎ°ú ÎÑ£Ïñ¥ ÏòàÏ∏° Í≤∞Í≥ºÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
ÏòàÏ∏° Í≤∞Í≥ºÏóêÏÑú Í∞ÄÏû• ÌôïÎ•†Ïù¥ ÎÜíÏùÄ ÌÜ†ÌÅ∞ÏùÑ ÏÑ†ÌÉùÌïòÏó¨ ÎåÄÎãµÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.

### üßæ **Dataset**

- [Í∞êÏÑ± ÎåÄÌôî ÎßêÎ≠âÏπò Îç∞Ïù¥ÌÑ∞ ÏÖã (AI Hub)](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=86)
- Ï∂îÍ∞Ä Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Î∞è ÌïôÏäµ

### üõ† **Requirements**
```
! pip install transformers
! pip install pytorch-lightning
! pip install torch
```

### ‚öæÔ∏è **Import**

```
import numpy as np
import pandas as pd
import torch
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning import LightningModule
from torch.utils.data import DataLoader, Dataset
from transformers.optimization import AdamW, get_cosine_schedule_with_warmup
from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel
import re

```
### **ü•å ÌÜ†ÌÅ∞**
```python
Q_TKN = "<usr>"
A_TKN = "<sys>"
BOS = '</s>'
EOS = '</s>'
MASK = '<unused0>'
SENT = '<unused1>'
PAD = '<pad>
```
- Q_TKN = "<usr>" : ÏßàÎ¨∏ Ïú†Ï†Ä ÌÜ†ÌÅ∞
- A_TKN = "<sys>" : ÎåÄÎãµ ÏãúÏä§ÌÖú ÌÜ†ÌÅ∞
- BOS = '</s>' : Î¨∏Ïû•Ïùò ÏãúÏûë
- EOS = '</s>' : Î¨∏Ïû•Ïùò ÎÅùÏùÑ
- MASK = '<unused0>' : ÎßàÏä§ÌÅ¨ Ï≤òÎ¶¨
- SENT = '<unused1>' : Î¨∏Ïû• Ï≤òÎ¶¨
- PAD = '<pad>' : Ìå®Îî© 

### üéæ **Hyper Parameter**

```
# Setting parameters
learning_rate = 3e-5
criterion = torch.nn.CrossEntropyLoss(reduction="mean")
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
epoch = 70
Sneg = -1e18
```

***ÌïòÏù¥Ìçº ÌååÎùºÎØ∏ÌÑ∞ ÏÖãÌåÖ***
- criterion :  CrossEntropyLoss 
- optimizer : Adam 

### üßö‚Äç‚ôÄÔ∏è **KoGPT2 Chatbot Dataset**

```python 
class ChatbotDataset(Dataset):
    def __init__(self, chats, max_len=100):  # Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Ï†ÑÏ≤òÎ¶¨Î•º Ìï¥Ï£ºÎäî Î∂ÄÎ∂Ñ
        self._data = chats
        self.max_len = max_len
        self.q_token = Q_TKN
        self.a_token = A_TKN
        self.sent_token = SENT
        self.eos = EOS
        self.mask = MASK
        self.tokenizer = koGPT2_TOKENIZER

    def __len__(self):  # chatbotdata Ïùò Í∏∏Ïù¥Î•º Î¶¨ÌÑ¥ÌïúÎã§.
        return len(self._data)

    def __getitem__(self, idx):  # Î°úÎìúÌïú Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï∞®Î°ÄÏ∞®Î°Ä DataLoaderÎ°ú ÎÑòÍ≤®Ï£ºÎäî Î©îÏÑúÎìú
        turn = self._data.iloc[idx]
        q = turn["ÏÇ¨ÎûåÎ¨∏Ïû•1"]  # ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò®Îã§.
        q = re.sub(r"([?.!,])", r" ", q)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.

        a = turn["ÏãúÏä§ÌÖúÎ¨∏Ïû•1"]  # ÎãµÎ≥ÄÏùÑ Í∞ÄÏ†∏Ïò®Îã§.
        a = re.sub(r"([?.!,])", r" ", a)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.

        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)
        q_len = len(q_toked)

        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)
        a_len = len(a_toked)

        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥
        if q_len > self.max_len:
            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥
            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥
                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú 
                q_len = len(q_toked)
                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥
            a_toked = a_toked[:a_len]
            a_len = len(a_toked)

        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥ + ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥
        if q_len + a_len > self.max_len:
            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥
            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥
                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú 
                q_len = len(q_toked)
                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥
            a_toked = a_toked[:a_len]
            a_len = len(a_toked)

        # ÎãµÎ≥Ä labels = [mask, mask, ...., mask, ..., <bos>,..ÎãµÎ≥Ä.. <eos>, <pad>....]
        labels = [self.mask,] * q_len + a_toked[1:]

        # mask = ÏßàÎ¨∏Í∏∏Ïù¥ 0 + ÎãµÎ≥ÄÍ∏∏Ïù¥ 1 + ÎÇòÎ®∏ÏßÄ 0
        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)
        # ÎãµÎ≥Ä labelsÏùÑ index Î°ú ÎßåÎì†Îã§.
        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)
        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING
        while len(labels_ids) < self.max_len:
            labels_ids += [self.tokenizer.pad_token_id]

        # ÏßàÎ¨∏ + ÎãµÎ≥ÄÏùÑ index Î°ú ÎßåÎì†Îã§.    
        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)
        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING
        while len(token_ids) < self.max_len:
            token_ids += [self.tokenizer.pad_token_id]

        #ÏßàÎ¨∏+ÎãµÎ≥Ä, ÎßàÏä§ÌÅ¨, ÎãµÎ≥Ä
        return (token_ids, np.array(mask), labels_ids)

def collate_batch(batch):
    data = [item[0] for item in batch]
    mask = [item[1] for item in batch]
    label = [item[2] for item in batch]
    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)
```


### üî´ **ÌÜ†ÌÅ¨ ÎÇòÏù¥Ï†Ä / Î™®Îç∏ Ï†ïÏùò**

```python
koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained("skt/kogpt2-base-v2",
            bos_token=BOS, eos_token=EOS, unk_token='<unk>',
            pad_token=PAD, mask_token=MASK) 
model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')
```

- skt/kogpt2-base-v2 Î™®Îç∏Ïóê ÎåÄÌïú ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î°úÎìú
- GPT2LMHeadModelÏùÄ GPT-2 Î™®Îç∏ Î°úÎìú, 'skt/kogpt2-base-v2' Î™®Îç∏

### üíø **Îç∞Ïù¥ÌÑ∞ Î°úÎìú/ Ï†ÑÏ≤òÎ¶¨**

```python
import urllib.request

Chatbot_Data = pd.read_csv("./data/Í∞êÏÑ±ÎåÄÌôîÎßêÎ≠âÏπò(ÏµúÏ¢ÖÎç∞Ïù¥ÌÑ∞)_Training.csv", encoding="cp949")
Chatbot_Data = Chatbot_Data[:51629]
Chatbot_Data.head()
train_set = ChatbotDataset(Chatbot_Data, max_len=100)
train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)
```

### üß∏ **Î™®Îç∏ ÌïôÏäµ**

```python
import matplotlib.pyplot as plt

losses = []
X = []
Y = []
print("start")
for epoch in range(epoch):
    print(epoch)
    X.append(epoch)
    for batch_idx, samples in enumerate(train_dataloader):
        optimizer.zero_grad()
        token_ids, mask, label = samples
        token_ids = token_ids.to(device)
        mask = mask.to(device)
        label = label.to(device)
        out = model(token_ids)        
        out = out.logits.to(device)
        
        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2).to(device)
        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out)).to(device)
        loss = criterion(mask_out.transpose(2, 1), label).to(device)
        
        avg_loss = loss.sum() / mask.sum()
        avg_loss.backward()
        optimizer.step()
    Y.append(loss.data.cpu().numpy())
print("end")

```
- train_dataloaderÏóêÏÑú token_ids, mask, label Í∞íÏùÑ Ìï†Îãπ

- optimizerÎ•º Ï¥àÍ∏∞ÌôîÌïòÍ≥†, Î™®Îç∏Ïùò Ï∂úÎ†• Í∞í outÏùÑ Í≥ÑÏÇ∞, logits Î©îÏÑúÎìúÎ•º Ïù¥Ïö©ÌïòÏó¨ Î°úÏßì Í∞íÏùÑ Í≥ÑÏÇ∞

- mask Í∞íÏùÑ 3Ï∞®ÏõêÏúºÎ°ú ÌôïÏû•, outÍ≥º ÎèôÏùºÌïú ÌÅ¨Í∏∞Î°ú Î∞òÎ≥µÌïòÏó¨ mask_3dÎ•º ÏÉùÏÑ±.
- torch.where Î©îÏÑúÎìúÎ•º Ïù¥Ïö©ÌïòÏó¨ maskÍ∞Ä 1Ïù∏ ÏúÑÏπòÎäî out Í∞íÏùÑ, 0Ïù∏ ÏúÑÏπòÎäî Negative infinity Í∞íÏùÑ Í∞ÄÏßÄÎäî ÌÖêÏÑúÎ•º ÏÉùÏÑ±ÌïòÏó¨ mask_out Î≥ÄÏàòÏóê Ìï†Îãπ

- ÏÜêÏã§ Ìï®Ïàò(criterion)Î•º Í≥ÑÏÇ∞ÌïòÍ≥†, loss Í∞íÏùÑ Ïù¥Ïö©ÌïòÏó¨ ÌòÑÏû¨ ÏÜêÏã§ Í∞íÏùÑ Íµ¨Ìï©ÎãàÎã§. Ïù¥Îïå, ÏÜêÏã§ Í∞íÏùò ÌèâÍ∑†ÏùÑ Íµ¨ÌïòÍ∏∞ ÏúÑÌï¥ avg_loss Î≥ÄÏàòÎ•º Í≥ÑÏÇ∞

- backward Î©îÏÑúÎìúÎ•º Ïù¥Ïö©ÌïòÏó¨ Í∑∏ÎùºÎîîÏñ∏Ìä∏Î•º Í≥ÑÏÇ∞ÌïòÍ≥†, step Î©îÏÑúÎìúÎ•º Ïù¥Ïö©ÌïòÏó¨ ÌååÎùºÎØ∏ÌÑ∞Î•º ÏóÖÎç∞Ïù¥Ìä∏

### üì§ **Predict**

```python
def kogpt(input_text):
    q = input_text
    a = ""
    sent = ""
    while True:
        input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + sent + A_TKN + a)).unsqueeze(dim=0)
        pred = model(input_ids)
        pred = pred.logits
        gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().tolist())[-1]
        if gen == EOS:
            break
        a += gen.replace("‚ñÅ", " ")
    return a
```

-  koGPT2 Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏûÖÎ†•Îêú ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎåÄÎãµÏùÑ ÏÉùÏÑ±ÌïòÎäî Ìï®Ïàò
- Ïù∏ÏΩîÎî©Îêú input_idsÎ•º Î™®Îç∏Ïóê ÏûÖÎ†•ÏúºÎ°ú ÎÑ£Ïñ¥ pred Î≥ÄÏàòÏóê ÏòàÏ∏° Í≤∞Í≥ºÎ•º Ï†ÄÏû•
- torch.argmax Ìï®ÏàòÎ•º Ïù¥Ïö©ÌïòÏó¨ Í∞ÄÏû• ÌôïÎ•†Ïù¥ ÎÜíÏùÄ ÌÜ†ÌÅ∞ÏùÑ ÏÑ†ÌÉùÌïòÍ≥†, Ïù¥Î•º gen Î≥ÄÏàòÏóê Ï†ÄÏû•, Ïù¥Îïå convert_ids_to_tokens Ìï®ÏàòÎ•º Ïù¥Ïö©ÌïòÏó¨ ÏÑ†ÌÉùÎêú ÌÜ†ÌÅ∞ÏùÑ Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò

- gen Î≥ÄÏàòÍ∞Ä EOSÏù∏ Í≤ΩÏö∞, ÏÉùÏÑ± Í≥ºÏ†ïÏùÑ ÎßàÏπ®. Í∑∏Î†áÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ genÏóê ÎåÄÌïú Í∞íÏùÑ aÏóê Ï∂îÍ∞Ä

### üì© **OUT**

```
input_text = "Ïò§Îäò Í∞ëÏûêÍ∏∞ ÎÇ†Ïî®Í∞Ä Ï∂îÏõåÏ†∏ÏÑú ÎÜÄÎûêÏñ¥"
kogpt(sentence) # "ÎÇ†Ïî®Í∞Ä ÎßéÏù¥ Ï∂îÏõåÏ°åÍµ∞Ïöî"
```



## üí° **Í∞êÏÑ± Ï±óÎ¥á üëâ KoBERT**



### **Îç∞Ïù¥ÌÑ∞ ÏÖã**
- AI¬†Hub¬†Ï†úÍ≥µ,¬†Ïõ∞ÎãàÏä§¬†ÎåÄÌôî¬†Ïä§ÌÅ¨Î¶ΩÌä∏¬†Îç∞Ïù¥ÌÑ∞ÏÖã (_ÌòÑÏû¨ ÌéòÏù¥ÏßÄ ÏóÜÏùå_)

### ‚ú® Í≤∞Í≥ºÎ¨º
**Loss**
- CrossEntropyLoss() - ÍµêÏ∞® ÏóîÌä∏Î°úÌîº Ïò§Ï∞®
- <img src = "https://user-images.githubusercontent.com/109534450/229016538-98df19eb-1bd3-4f78-8aff-abf498ca8759.png" width="35%" height="35%">
- Îëê¬†ÌôïÎ•†¬†Î∂ÑÌè¨Ïùò¬†Ï∞®Ïù¥Î•º¬†Íµ¨ÌïòÍ∏∞¬†ÏúÑÌï¥ÏÑú¬†ÏÇ¨Ïö©Îê©ÎãàÎã§.
- Ïã§Ï†ú¬†Îç∞Ïù¥ÌÑ∞Ïùò¬†ÌôïÎ•†¬†Î∂ÑÌè¨ÏôÄ, ÌïôÏäµÎêú Î™®Îç∏Ïù¥¬†Í≥ÑÏÇ∞Ìïú ÌôïÎ•† Î∂ÑÌè¨Ïùò Ï∞®Ïù¥Î•º Íµ¨ÌïòÎäîÎç∞ ÏÇ¨Ïö©ÎêúÎã§.

<img src = "https://user-images.githubusercontent.com/109534450/229391092-b4e0e45c-8d9d-4ff4-b7b3-c1716b6b945f.png" width="55%" height="55%">


### **üîß Í∞úÎ∞ú ÌôòÍ≤Ω**
- Google Colab
- Jupyter Hub


## üèÉ Team Group

**Front End** <br />
üòé _ÍπÄÏßÄÌôò_
üòé _Î•òÏõêÏ∞Ω_

**Back End** <br />
üòé _Ïù¥ÏßÄÏùÄ_
üòé _Ï†ïÌòÑÏÑù_

**AI** <br />
üíÆ*ÏÜåÏ±ÑÎ¶∞*
üíÆ _Ï°∞Ïö©Í¥Ä_

<br />
# Î∏åÎûúÏπò Ï†ÑÎûµ

- main: Ï∂úÏãú Ï†Ñ ÍπåÏßÄ ÏûëÏóÖ X
  - dev : Î∂ÑÏïºÎ≥Ñ Í∏∞Îä• Ìï©Ï≥êÏÑú ÌÖåÏä§Ìä∏
    - AI : AI Í¥ÄÎ†® ÏôÑÎ£åÎêú Í∏∞Îä•
      - cho
      - so
    - BE : BE Í¥ÄÎ†® ÏôÑÎ£åÎêú Í∏∞Îä•
      - cheong
      - lee
    - FE : FE Í¥ÄÎ†® ÏôÑÎ£åÎêú Í∏∞Îä•
      - kim
      - ryu

# Commit Message Convention

YYMMDD_AI_AUTHOR_TYPE_CONTENT

230207_BE_CHEONG_INIT_AddUserRepository

## TYPE

- INIT : Ïã†Í∑ú ÌååÏùº ÏÉùÏÑ±
- FEAT : Ïã†Í∑ú Í∏∞Îä• ÏÉùÏÑ±
- MODI : Í∏∞Îä• ÏàòÏ†ï
- FIX : Î≤ÑÍ∑∏ ÏàòÏ†ï
- TEST : ÌÖåÏä§Ìä∏
